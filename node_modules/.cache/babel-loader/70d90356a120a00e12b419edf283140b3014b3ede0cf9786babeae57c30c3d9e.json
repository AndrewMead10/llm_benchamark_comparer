{"ast":null,"code":"// This file provides mock responses for OpenRouter API calls when testing locally\n\nexport const generateMockResponse = (model, prompt) => {\n  // Simulate network delay\n  return new Promise(resolve => {\n    setTimeout(() => {\n      resolve({\n        id: `mockapi-${Date.now()}`,\n        object: \"chat.completion\",\n        created: Math.floor(Date.now() / 1000),\n        model: model,\n        choices: [{\n          message: {\n            role: \"assistant\",\n            content: getMockResponseContent(model, prompt)\n          },\n          index: 0,\n          finish_reason: \"stop\"\n        }],\n        usage: {\n          prompt_tokens: prompt.length / 4,\n          completion_tokens: 250,\n          total_tokens: prompt.length / 4 + 250\n        }\n      });\n    }, 2000);\n  });\n};\n\n// Generate different mock responses for different models\nconst getMockResponseContent = (model, prompt) => {\n  const responses = {\n    \"openai/gpt-4-turbo\": `As GPT-4, I would approach this by first analyzing the requirements in detail. ${prompt} requires a comprehensive solution that balances technical implementation with user experience. I would recommend starting with a user research phase to understand the specific needs, followed by prototyping and iterative development.`,\n    \"anthropic/claude-3-opus\": `Based on your request about ${prompt}, I'd like to offer a thoughtful, nuanced response. First, it's important to consider the ethical implications. Second, we should examine the technical feasibility. Third, let's consider implementation strategies that prioritize clarity and user safety.`,\n    \"google/gemini-pro\": `Regarding your inquiry about ${prompt}, here's my analysis: This represents an opportunity to leverage cutting-edge AI capabilities while maintaining responsible deployment practices. I would recommend a phased approach with continuous evaluation metrics.`,\n    \"meta-llama/llama-3-70b-instruct\": `For ${prompt}, I think we should consider the following approach: 1) Define clear success metrics, 2) Establish a baseline using existing solutions, 3) Develop an implementation plan with careful attention to both performance and ethical considerations, 4) Test extensively with diverse user groups.`,\n    \"openai/gpt-3.5-turbo\": `To address ${prompt}, I suggest implementing a solution that combines machine learning techniques with human oversight. This could involve training a model on relevant data, implementing a user-friendly interface, and establishing clear escalation paths for edge cases.`,\n    \"mistralai/mistral-7b-instruct\": `For ${prompt}, here's what I recommend: First analyze your specific requirements and constraints. Then explore available open-source and commercial solutions. Finally, develop a customized approach that leverages the strengths of foundation models while addressing their limitations.`\n  };\n  return responses[model] || `This is a mock response for ${model} regarding ${prompt}. In a real implementation, this would be an actual response from the AI model.`;\n};\n\n// Export a function to use instead of fetch for testing\nexport const mockOpenRouterFetch = async (url, options) => {\n  console.log(\"Using mock OpenRouter API\");\n  const {\n    model,\n    messages\n  } = JSON.parse(options.body);\n  const prompt = messages[0].content;\n  const mockResponse = await generateMockResponse(model, prompt);\n  return {\n    ok: true,\n    json: async () => mockResponse\n  };\n};","map":{"version":3,"names":["generateMockResponse","model","prompt","Promise","resolve","setTimeout","id","Date","now","object","created","Math","floor","choices","message","role","content","getMockResponseContent","index","finish_reason","usage","prompt_tokens","length","completion_tokens","total_tokens","responses","mockOpenRouterFetch","url","options","console","log","messages","JSON","parse","body","mockResponse","ok","json"],"sources":["/Users/mariagorskikh/hackathon moestro/ai-model-advisor/src/utils/mockOpenRouterAPI.js"],"sourcesContent":["// This file provides mock responses for OpenRouter API calls when testing locally\n\nexport const generateMockResponse = (model, prompt) => {\n  // Simulate network delay\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      resolve({\n        id: `mockapi-${Date.now()}`,\n        object: \"chat.completion\",\n        created: Math.floor(Date.now() / 1000),\n        model: model,\n        choices: [\n          {\n            message: {\n              role: \"assistant\",\n              content: getMockResponseContent(model, prompt)\n            },\n            index: 0,\n            finish_reason: \"stop\"\n          }\n        ],\n        usage: {\n          prompt_tokens: prompt.length / 4,\n          completion_tokens: 250,\n          total_tokens: prompt.length / 4 + 250\n        }\n      });\n    }, 2000);\n  });\n};\n\n// Generate different mock responses for different models\nconst getMockResponseContent = (model, prompt) => {\n  const responses = {\n    \"openai/gpt-4-turbo\": `As GPT-4, I would approach this by first analyzing the requirements in detail. ${prompt} requires a comprehensive solution that balances technical implementation with user experience. I would recommend starting with a user research phase to understand the specific needs, followed by prototyping and iterative development.`,\n    \n    \"anthropic/claude-3-opus\": `Based on your request about ${prompt}, I'd like to offer a thoughtful, nuanced response. First, it's important to consider the ethical implications. Second, we should examine the technical feasibility. Third, let's consider implementation strategies that prioritize clarity and user safety.`,\n    \n    \"google/gemini-pro\": `Regarding your inquiry about ${prompt}, here's my analysis: This represents an opportunity to leverage cutting-edge AI capabilities while maintaining responsible deployment practices. I would recommend a phased approach with continuous evaluation metrics.`,\n    \n    \"meta-llama/llama-3-70b-instruct\": `For ${prompt}, I think we should consider the following approach: 1) Define clear success metrics, 2) Establish a baseline using existing solutions, 3) Develop an implementation plan with careful attention to both performance and ethical considerations, 4) Test extensively with diverse user groups.`,\n    \n    \"openai/gpt-3.5-turbo\": `To address ${prompt}, I suggest implementing a solution that combines machine learning techniques with human oversight. This could involve training a model on relevant data, implementing a user-friendly interface, and establishing clear escalation paths for edge cases.`,\n    \n    \"mistralai/mistral-7b-instruct\": `For ${prompt}, here's what I recommend: First analyze your specific requirements and constraints. Then explore available open-source and commercial solutions. Finally, develop a customized approach that leverages the strengths of foundation models while addressing their limitations.`\n  };\n  \n  return responses[model] || `This is a mock response for ${model} regarding ${prompt}. In a real implementation, this would be an actual response from the AI model.`;\n};\n\n// Export a function to use instead of fetch for testing\nexport const mockOpenRouterFetch = async (url, options) => {\n  console.log(\"Using mock OpenRouter API\");\n  const { model, messages } = JSON.parse(options.body);\n  const prompt = messages[0].content;\n  \n  const mockResponse = await generateMockResponse(model, prompt);\n  \n  return {\n    ok: true,\n    json: async () => mockResponse\n  };\n}; "],"mappings":"AAAA;;AAEA,OAAO,MAAMA,oBAAoB,GAAGA,CAACC,KAAK,EAAEC,MAAM,KAAK;EACrD;EACA,OAAO,IAAIC,OAAO,CAAEC,OAAO,IAAK;IAC9BC,UAAU,CAAC,MAAM;MACfD,OAAO,CAAC;QACNE,EAAE,EAAE,WAAWC,IAAI,CAACC,GAAG,CAAC,CAAC,EAAE;QAC3BC,MAAM,EAAE,iBAAiB;QACzBC,OAAO,EAAEC,IAAI,CAACC,KAAK,CAACL,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC;QACtCP,KAAK,EAAEA,KAAK;QACZY,OAAO,EAAE,CACP;UACEC,OAAO,EAAE;YACPC,IAAI,EAAE,WAAW;YACjBC,OAAO,EAAEC,sBAAsB,CAAChB,KAAK,EAAEC,MAAM;UAC/C,CAAC;UACDgB,KAAK,EAAE,CAAC;UACRC,aAAa,EAAE;QACjB,CAAC,CACF;QACDC,KAAK,EAAE;UACLC,aAAa,EAAEnB,MAAM,CAACoB,MAAM,GAAG,CAAC;UAChCC,iBAAiB,EAAE,GAAG;UACtBC,YAAY,EAAEtB,MAAM,CAACoB,MAAM,GAAG,CAAC,GAAG;QACpC;MACF,CAAC,CAAC;IACJ,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC;AACJ,CAAC;;AAED;AACA,MAAML,sBAAsB,GAAGA,CAAChB,KAAK,EAAEC,MAAM,KAAK;EAChD,MAAMuB,SAAS,GAAG;IAChB,oBAAoB,EAAE,kFAAkFvB,MAAM,4OAA4O;IAE1V,yBAAyB,EAAE,+BAA+BA,MAAM,+PAA+P;IAE/T,mBAAmB,EAAE,gCAAgCA,MAAM,2NAA2N;IAEtR,iCAAiC,EAAE,OAAOA,MAAM,gSAAgS;IAEhV,sBAAsB,EAAE,cAAcA,MAAM,2PAA2P;IAEvS,+BAA+B,EAAE,OAAOA,MAAM;EAChD,CAAC;EAED,OAAOuB,SAAS,CAACxB,KAAK,CAAC,IAAI,+BAA+BA,KAAK,cAAcC,MAAM,iFAAiF;AACtK,CAAC;;AAED;AACA,OAAO,MAAMwB,mBAAmB,GAAG,MAAAA,CAAOC,GAAG,EAAEC,OAAO,KAAK;EACzDC,OAAO,CAACC,GAAG,CAAC,2BAA2B,CAAC;EACxC,MAAM;IAAE7B,KAAK;IAAE8B;EAAS,CAAC,GAAGC,IAAI,CAACC,KAAK,CAACL,OAAO,CAACM,IAAI,CAAC;EACpD,MAAMhC,MAAM,GAAG6B,QAAQ,CAAC,CAAC,CAAC,CAACf,OAAO;EAElC,MAAMmB,YAAY,GAAG,MAAMnC,oBAAoB,CAACC,KAAK,EAAEC,MAAM,CAAC;EAE9D,OAAO;IACLkC,EAAE,EAAE,IAAI;IACRC,IAAI,EAAE,MAAAA,CAAA,KAAYF;EACpB,CAAC;AACH,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}