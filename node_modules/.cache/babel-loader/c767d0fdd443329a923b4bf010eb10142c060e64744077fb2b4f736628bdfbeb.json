{"ast":null,"code":"const MAESTRO_API_KEY = \"FiG5CA1uXiKXw6zTxkEpNWhUxK3iDQIA\";\nconst MAESTRO_API_URL = \"https://api.ai21.com/v1/studio/maestro/runs\";\n\n/**\n * Generates a test prompt based on the user's description of what they want to use AI for\n * @param {string} userDescription - The user's input describing their AI use case\n * @returns {Promise<string>} - The generated test prompt\n */\nexport const generateTestPrompt = async userDescription => {\n  try {\n    const response = await fetch(MAESTRO_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${MAESTRO_API_KEY}`\n      },\n      body: JSON.stringify({\n        input: `I want to test different AI models for the following use case: \"${userDescription}\". \n                Create a specific, detailed prompt that would effectively test an AI model's capability in this domain. \n                The prompt should be challenging but fair, revealing strengths and weaknesses of models.\n                Provide ONLY the prompt text with no additional commentary or explanations.`\n      })\n    });\n    if (!response.ok) {\n      const errorData = await response.json();\n      console.error('Error from Maestro API:', errorData);\n      throw new Error(`Maestro API error: ${errorData.detail || 'Unknown error'}`);\n    }\n    const data = await response.json();\n    const runId = data.id;\n\n    // Poll for completion\n    return await pollRunCompletion(runId);\n  } catch (error) {\n    console.error('Error generating test prompt:', error);\n    throw error;\n  }\n};\n\n/**\n * Evaluates the outputs from different AI models\n * @param {string} originalPrompt - The prompt used for testing\n * @param {Array} modelOutputs - Array of objects containing model outputs\n * @returns {Promise<Object>} - Evaluation results\n */\nexport const evaluateModelOutputs = async (originalPrompt, modelOutputs) => {\n  try {\n    // Format the outputs for Maestro\n    const formattedOutputs = modelOutputs.map(output => `Model: ${output.model.name}\\nOutput: ${output.output}\\n\\n`).join('');\n    const response = await fetch(MAESTRO_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${MAESTRO_API_KEY}`\n      },\n      body: JSON.stringify({\n        input: `You are an objective AI model evaluator. Below is a prompt and outputs from different AI models.\n                \n                ORIGINAL PROMPT:\n                ${originalPrompt}\n                \n                MODEL OUTPUTS:\n                ${formattedOutputs}\n                \n                Analyze each model's response and provide:\n                1. Individual evaluation for each model (strengths, weaknesses, accuracy, relevance)\n                2. Comparative analysis between the models\n                3. Objective numerical scores (1-10) for each model based on:\n                   - Accuracy and correctness\n                   - Comprehensiveness\n                   - Clarity and communication\n                   - Relevance to the prompt\n                4. Final ranking of the models from best to worst for this specific prompt\n                \n                Present your evaluation in a structured, easy-to-read format.`,\n        requirements: [{\n          name: \"objectivity\",\n          description: \"Evaluate models objectively without bias toward any specific provider\",\n          is_mandatory: true\n        }, {\n          name: \"comprehensive\",\n          description: \"Provide detailed analysis across all evaluation criteria\",\n          is_mandatory: true\n        }, {\n          name: \"structured\",\n          description: \"Present results in a clear, structured format with numerical scores and rankings\",\n          is_mandatory: true\n        }]\n      })\n    });\n    if (!response.ok) {\n      const errorData = await response.json();\n      console.error('Error from Maestro API:', errorData);\n      throw new Error(`Maestro API error: ${errorData.detail || 'Unknown error'}`);\n    }\n    const data = await response.json();\n    const runId = data.id;\n\n    // Poll for completion\n    return await pollRunCompletion(runId);\n  } catch (error) {\n    console.error('Error evaluating model outputs:', error);\n    throw error;\n  }\n};\n\n/**\n * Polls the Maestro API for the completion of a run\n * @param {string} runId - The ID of the Maestro run\n * @returns {Promise<string>} - The result of the run\n */\nconst pollRunCompletion = async runId => {\n  const maxAttempts = 30;\n  const delayMs = 1000;\n  for (let attempt = 0; attempt < maxAttempts; attempt++) {\n    try {\n      const response = await fetch(`https://api.ai21.com/studio/v1/maestro/runs/${runId}`, {\n        method: 'GET',\n        headers: {\n          'Authorization': `Bearer ${MAESTRO_API_KEY}`\n        }\n      });\n      if (!response.ok) {\n        const errorData = await response.json();\n        console.error(`Error polling run status (attempt ${attempt + 1}):`, errorData);\n        // Continue polling despite errors\n      } else {\n        const data = await response.json();\n        if (data.status === 'completed') {\n          return data.result.output;\n        } else if (data.status === 'failed') {\n          throw new Error(`Maestro run failed: ${data.error || 'Unknown error'}`);\n        }\n        // If still in progress, continue polling\n      }\n    } catch (error) {\n      console.error(`Error in polling attempt ${attempt + 1}:`, error);\n      // Continue polling despite errors\n    }\n\n    // Wait before the next poll\n    await new Promise(resolve => setTimeout(resolve, delayMs));\n  }\n  throw new Error(`Polling timed out after ${maxAttempts} attempts`);\n};\n\n/**\n * Mock function for testing without making actual API calls\n */\nexport const mockMaestroPromptGeneration = userDescription => {\n  return new Promise(resolve => {\n    setTimeout(() => {\n      // Generate mock test prompts based on the use case\n      const mockPrompts = {\n        \"math problems\": \"Solve the following problem step by step: A ball is thrown vertically upward with an initial velocity of 20 m/s from a height of 2 meters above the ground. How long will it take for the ball to hit the ground? (Use g = 9.8 m/s²)\",\n        \"customer service\": \"You are a customer service representative for an online electronics retailer. A customer has written to you saying they received a laptop with a cracked screen. They purchased it 35 days ago, and your return policy is 30 days. Craft a helpful, empathetic response that addresses their concern and provides possible solutions.\",\n        \"content generation\": \"Write a compelling product description for a new eco-friendly water bottle that keeps drinks cold for 24 hours and hot for 12 hours. The bottle is made from recycled materials, is BPA-free, and comes in three colors: ocean blue, forest green, and sunset orange. The target audience is environmentally-conscious young professionals.\",\n        \"coding\": \"Write a Python function that takes a list of integers and returns the longest consecutive sequence of integers in the list. For example, if the input is [100, 4, 200, 1, 3, 2], the output should be [1, 2, 3, 4]. Include comments explaining your approach.\"\n      };\n\n      // Find a matching prompt or generate a generic one\n      let testPrompt = \"Unknown use case. Please try a more specific description.\";\n      for (const [key, value] of Object.entries(mockPrompts)) {\n        if (userDescription.toLowerCase().includes(key)) {\n          testPrompt = value;\n          break;\n        }\n      }\n\n      // If no specific match, use this generic math problem for testing\n      if (testPrompt === \"Unknown use case. Please try a more specific description.\") {\n        testPrompt = \"Solve the following math problem, showing all your steps: If f(x) = 2x² - 3x + 1, find f'(x) and calculate f'(2).\";\n      }\n      resolve(testPrompt);\n    }, 1500);\n  });\n};\n\n/**\n * Mock function for evaluation without making actual API calls\n */\nexport const mockMaestroEvaluation = (originalPrompt, modelOutputs) => {\n  return new Promise(resolve => {\n    setTimeout(() => {\n      // Create a mock evaluation\n      const modelNames = modelOutputs.map(output => output.model.name);\n      const mockEvaluation = `\n## Individual Model Evaluations\n\n${modelOutputs.map((output, index) => `\n### ${output.model.name}\n- **Accuracy/Correctness**: ${7 + Math.floor(Math.random() * 4)}/10\n- **Comprehensiveness**: ${6 + Math.floor(Math.random() * 5)}/10\n- **Clarity**: ${6 + Math.floor(Math.random() * 5)}/10\n- **Relevance**: ${7 + Math.floor(Math.random() * 4)}/10\n\n**Strengths**: ${getRandomStrength(output.model.name)}\n**Weaknesses**: ${getRandomWeakness(output.model.name)}\n`).join('')}\n\n## Comparative Analysis\n\nThe models demonstrated varying approaches to the prompt \"${originalPrompt.substring(0, 50)}...\".\n\n${modelNames[0]} provided ${Math.random() > 0.5 ? \"the most accurate\" : \"a comprehensive\"} response, while ${modelNames[modelNames.length - 1]} ${Math.random() > 0.5 ? \"focused more on clarity\" : \"gave more detailed explanations\"}.\n\n## Final Rankings\n\n1. ${modelNames[Math.floor(Math.random() * modelNames.length)]} - Overall score: ${Math.floor(Math.random() * 3) + 8}/10\n${modelNames.slice(0, modelNames.length - 1).map((name, idx) => `${idx + 2}. ${name} - Overall score: ${Math.floor(Math.random() * 3) + 6}/10`).join('\\n')}\n      `;\n      resolve(mockEvaluation);\n    }, 3000);\n  });\n};\n\n// Helper functions for mock data\nfunction getRandomStrength(modelName) {\n  const strengths = [\"Provided a clear and concise explanation\", \"Effectively broke down complex concepts\", \"Offered accurate calculations with proper methodology\", \"Demonstrated excellent reasoning capabilities\", \"Included helpful examples to illustrate key points\"];\n  return strengths[Math.floor(Math.random() * strengths.length)];\n}\nfunction getRandomWeakness(modelName) {\n  const weaknesses = [\"Could have provided more detailed explanations\", \"Some minor calculation errors present\", \"Response could be more structured for clarity\", \"Did not fully address all aspects of the prompt\", \"Used unnecessarily complex language in some sections\"];\n  return weaknesses[Math.floor(Math.random() * weaknesses.length)];\n}","map":{"version":3,"names":["MAESTRO_API_KEY","MAESTRO_API_URL","generateTestPrompt","userDescription","response","fetch","method","headers","body","JSON","stringify","input","ok","errorData","json","console","error","Error","detail","data","runId","id","pollRunCompletion","evaluateModelOutputs","originalPrompt","modelOutputs","formattedOutputs","map","output","model","name","join","requirements","description","is_mandatory","maxAttempts","delayMs","attempt","status","result","Promise","resolve","setTimeout","mockMaestroPromptGeneration","mockPrompts","testPrompt","key","value","Object","entries","toLowerCase","includes","mockMaestroEvaluation","modelNames","mockEvaluation","index","Math","floor","random","getRandomStrength","getRandomWeakness","substring","length","slice","idx","modelName","strengths","weaknesses"],"sources":["/Users/mariagorskikh/hackathon moestro/ai-model-advisor/src/utils/maestroAPI.js"],"sourcesContent":["const MAESTRO_API_KEY = \"FiG5CA1uXiKXw6zTxkEpNWhUxK3iDQIA\";\nconst MAESTRO_API_URL = \"https://api.ai21.com/v1/studio/maestro/runs\";\n\n/**\n * Generates a test prompt based on the user's description of what they want to use AI for\n * @param {string} userDescription - The user's input describing their AI use case\n * @returns {Promise<string>} - The generated test prompt\n */\nexport const generateTestPrompt = async (userDescription) => {\n  try {\n    const response = await fetch(MAESTRO_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${MAESTRO_API_KEY}`\n      },\n      body: JSON.stringify({\n        input: `I want to test different AI models for the following use case: \"${userDescription}\". \n                Create a specific, detailed prompt that would effectively test an AI model's capability in this domain. \n                The prompt should be challenging but fair, revealing strengths and weaknesses of models.\n                Provide ONLY the prompt text with no additional commentary or explanations.`\n      })\n    });\n\n    if (!response.ok) {\n      const errorData = await response.json();\n      console.error('Error from Maestro API:', errorData);\n      throw new Error(`Maestro API error: ${errorData.detail || 'Unknown error'}`);\n    }\n\n    const data = await response.json();\n    const runId = data.id;\n    \n    // Poll for completion\n    return await pollRunCompletion(runId);\n  } catch (error) {\n    console.error('Error generating test prompt:', error);\n    throw error;\n  }\n};\n\n/**\n * Evaluates the outputs from different AI models\n * @param {string} originalPrompt - The prompt used for testing\n * @param {Array} modelOutputs - Array of objects containing model outputs\n * @returns {Promise<Object>} - Evaluation results\n */\nexport const evaluateModelOutputs = async (originalPrompt, modelOutputs) => {\n  try {\n    // Format the outputs for Maestro\n    const formattedOutputs = modelOutputs.map(output => \n      `Model: ${output.model.name}\\nOutput: ${output.output}\\n\\n`\n    ).join('');\n    \n    const response = await fetch(MAESTRO_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${MAESTRO_API_KEY}`\n      },\n      body: JSON.stringify({\n        input: `You are an objective AI model evaluator. Below is a prompt and outputs from different AI models.\n                \n                ORIGINAL PROMPT:\n                ${originalPrompt}\n                \n                MODEL OUTPUTS:\n                ${formattedOutputs}\n                \n                Analyze each model's response and provide:\n                1. Individual evaluation for each model (strengths, weaknesses, accuracy, relevance)\n                2. Comparative analysis between the models\n                3. Objective numerical scores (1-10) for each model based on:\n                   - Accuracy and correctness\n                   - Comprehensiveness\n                   - Clarity and communication\n                   - Relevance to the prompt\n                4. Final ranking of the models from best to worst for this specific prompt\n                \n                Present your evaluation in a structured, easy-to-read format.`,\n        requirements: [\n          {\n            name: \"objectivity\",\n            description: \"Evaluate models objectively without bias toward any specific provider\",\n            is_mandatory: true\n          },\n          {\n            name: \"comprehensive\",\n            description: \"Provide detailed analysis across all evaluation criteria\",\n            is_mandatory: true\n          },\n          {\n            name: \"structured\",\n            description: \"Present results in a clear, structured format with numerical scores and rankings\",\n            is_mandatory: true\n          }\n        ]\n      })\n    });\n\n    if (!response.ok) {\n      const errorData = await response.json();\n      console.error('Error from Maestro API:', errorData);\n      throw new Error(`Maestro API error: ${errorData.detail || 'Unknown error'}`);\n    }\n\n    const data = await response.json();\n    const runId = data.id;\n    \n    // Poll for completion\n    return await pollRunCompletion(runId);\n  } catch (error) {\n    console.error('Error evaluating model outputs:', error);\n    throw error;\n  }\n};\n\n/**\n * Polls the Maestro API for the completion of a run\n * @param {string} runId - The ID of the Maestro run\n * @returns {Promise<string>} - The result of the run\n */\nconst pollRunCompletion = async (runId) => {\n  const maxAttempts = 30;\n  const delayMs = 1000;\n  \n  for (let attempt = 0; attempt < maxAttempts; attempt++) {\n    try {\n      const response = await fetch(`https://api.ai21.com/studio/v1/maestro/runs/${runId}`, {\n        method: 'GET',\n        headers: {\n          'Authorization': `Bearer ${MAESTRO_API_KEY}`\n        }\n      });\n      \n      if (!response.ok) {\n        const errorData = await response.json();\n        console.error(`Error polling run status (attempt ${attempt + 1}):`, errorData);\n        // Continue polling despite errors\n      } else {\n        const data = await response.json();\n        \n        if (data.status === 'completed') {\n          return data.result.output;\n        } else if (data.status === 'failed') {\n          throw new Error(`Maestro run failed: ${data.error || 'Unknown error'}`);\n        }\n        // If still in progress, continue polling\n      }\n    } catch (error) {\n      console.error(`Error in polling attempt ${attempt + 1}:`, error);\n      // Continue polling despite errors\n    }\n    \n    // Wait before the next poll\n    await new Promise(resolve => setTimeout(resolve, delayMs));\n  }\n  \n  throw new Error(`Polling timed out after ${maxAttempts} attempts`);\n};\n\n/**\n * Mock function for testing without making actual API calls\n */\nexport const mockMaestroPromptGeneration = (userDescription) => {\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      // Generate mock test prompts based on the use case\n      const mockPrompts = {\n        \"math problems\": \"Solve the following problem step by step: A ball is thrown vertically upward with an initial velocity of 20 m/s from a height of 2 meters above the ground. How long will it take for the ball to hit the ground? (Use g = 9.8 m/s²)\",\n        \"customer service\": \"You are a customer service representative for an online electronics retailer. A customer has written to you saying they received a laptop with a cracked screen. They purchased it 35 days ago, and your return policy is 30 days. Craft a helpful, empathetic response that addresses their concern and provides possible solutions.\",\n        \"content generation\": \"Write a compelling product description for a new eco-friendly water bottle that keeps drinks cold for 24 hours and hot for 12 hours. The bottle is made from recycled materials, is BPA-free, and comes in three colors: ocean blue, forest green, and sunset orange. The target audience is environmentally-conscious young professionals.\",\n        \"coding\": \"Write a Python function that takes a list of integers and returns the longest consecutive sequence of integers in the list. For example, if the input is [100, 4, 200, 1, 3, 2], the output should be [1, 2, 3, 4]. Include comments explaining your approach.\"\n      };\n      \n      // Find a matching prompt or generate a generic one\n      let testPrompt = \"Unknown use case. Please try a more specific description.\";\n      \n      for (const [key, value] of Object.entries(mockPrompts)) {\n        if (userDescription.toLowerCase().includes(key)) {\n          testPrompt = value;\n          break;\n        }\n      }\n      \n      // If no specific match, use this generic math problem for testing\n      if (testPrompt === \"Unknown use case. Please try a more specific description.\") {\n        testPrompt = \"Solve the following math problem, showing all your steps: If f(x) = 2x² - 3x + 1, find f'(x) and calculate f'(2).\";\n      }\n      \n      resolve(testPrompt);\n    }, 1500);\n  });\n};\n\n/**\n * Mock function for evaluation without making actual API calls\n */\nexport const mockMaestroEvaluation = (originalPrompt, modelOutputs) => {\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      // Create a mock evaluation\n      const modelNames = modelOutputs.map(output => output.model.name);\n      const mockEvaluation = `\n## Individual Model Evaluations\n\n${modelOutputs.map((output, index) => `\n### ${output.model.name}\n- **Accuracy/Correctness**: ${7 + Math.floor(Math.random() * 4)}/10\n- **Comprehensiveness**: ${6 + Math.floor(Math.random() * 5)}/10\n- **Clarity**: ${6 + Math.floor(Math.random() * 5)}/10\n- **Relevance**: ${7 + Math.floor(Math.random() * 4)}/10\n\n**Strengths**: ${getRandomStrength(output.model.name)}\n**Weaknesses**: ${getRandomWeakness(output.model.name)}\n`).join('')}\n\n## Comparative Analysis\n\nThe models demonstrated varying approaches to the prompt \"${originalPrompt.substring(0, 50)}...\".\n\n${modelNames[0]} provided ${Math.random() > 0.5 ? \"the most accurate\" : \"a comprehensive\"} response, while ${modelNames[modelNames.length-1]} ${Math.random() > 0.5 ? \"focused more on clarity\" : \"gave more detailed explanations\"}.\n\n## Final Rankings\n\n1. ${modelNames[Math.floor(Math.random() * modelNames.length)]} - Overall score: ${Math.floor(Math.random() * 3) + 8}/10\n${modelNames.slice(0, modelNames.length-1).map((name, idx) => `${idx+2}. ${name} - Overall score: ${Math.floor(Math.random() * 3) + 6}/10`).join('\\n')}\n      `;\n      \n      resolve(mockEvaluation);\n    }, 3000);\n  });\n};\n\n// Helper functions for mock data\nfunction getRandomStrength(modelName) {\n  const strengths = [\n    \"Provided a clear and concise explanation\",\n    \"Effectively broke down complex concepts\",\n    \"Offered accurate calculations with proper methodology\",\n    \"Demonstrated excellent reasoning capabilities\",\n    \"Included helpful examples to illustrate key points\"\n  ];\n  return strengths[Math.floor(Math.random() * strengths.length)];\n}\n\nfunction getRandomWeakness(modelName) {\n  const weaknesses = [\n    \"Could have provided more detailed explanations\",\n    \"Some minor calculation errors present\",\n    \"Response could be more structured for clarity\",\n    \"Did not fully address all aspects of the prompt\",\n    \"Used unnecessarily complex language in some sections\"\n  ];\n  return weaknesses[Math.floor(Math.random() * weaknesses.length)];\n} "],"mappings":"AAAA,MAAMA,eAAe,GAAG,kCAAkC;AAC1D,MAAMC,eAAe,GAAG,6CAA6C;;AAErE;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,kBAAkB,GAAG,MAAOC,eAAe,IAAK;EAC3D,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAACJ,eAAe,EAAE;MAC5CK,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE,UAAUP,eAAe;MAC5C,CAAC;MACDQ,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBC,KAAK,EAAE,mEAAmER,eAAe;AACjG;AACA;AACA;MACM,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACC,QAAQ,CAACQ,EAAE,EAAE;MAChB,MAAMC,SAAS,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;MACvCC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEH,SAAS,CAAC;MACnD,MAAM,IAAII,KAAK,CAAC,sBAAsBJ,SAAS,CAACK,MAAM,IAAI,eAAe,EAAE,CAAC;IAC9E;IAEA,MAAMC,IAAI,GAAG,MAAMf,QAAQ,CAACU,IAAI,CAAC,CAAC;IAClC,MAAMM,KAAK,GAAGD,IAAI,CAACE,EAAE;;IAErB;IACA,OAAO,MAAMC,iBAAiB,CAACF,KAAK,CAAC;EACvC,CAAC,CAAC,OAAOJ,KAAK,EAAE;IACdD,OAAO,CAACC,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;IACrD,MAAMA,KAAK;EACb;AACF,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMO,oBAAoB,GAAG,MAAAA,CAAOC,cAAc,EAAEC,YAAY,KAAK;EAC1E,IAAI;IACF;IACA,MAAMC,gBAAgB,GAAGD,YAAY,CAACE,GAAG,CAACC,MAAM,IAC9C,UAAUA,MAAM,CAACC,KAAK,CAACC,IAAI,aAAaF,MAAM,CAACA,MAAM,MACvD,CAAC,CAACG,IAAI,CAAC,EAAE,CAAC;IAEV,MAAM3B,QAAQ,GAAG,MAAMC,KAAK,CAACJ,eAAe,EAAE;MAC5CK,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE,UAAUP,eAAe;MAC5C,CAAC;MACDQ,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBC,KAAK,EAAE;AACf;AACA;AACA,kBAAkBa,cAAc;AAChC;AACA;AACA,kBAAkBE,gBAAgB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E;QACtEM,YAAY,EAAE,CACZ;UACEF,IAAI,EAAE,aAAa;UACnBG,WAAW,EAAE,uEAAuE;UACpFC,YAAY,EAAE;QAChB,CAAC,EACD;UACEJ,IAAI,EAAE,eAAe;UACrBG,WAAW,EAAE,0DAA0D;UACvEC,YAAY,EAAE;QAChB,CAAC,EACD;UACEJ,IAAI,EAAE,YAAY;UAClBG,WAAW,EAAE,kFAAkF;UAC/FC,YAAY,EAAE;QAChB,CAAC;MAEL,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAAC9B,QAAQ,CAACQ,EAAE,EAAE;MAChB,MAAMC,SAAS,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;MACvCC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEH,SAAS,CAAC;MACnD,MAAM,IAAII,KAAK,CAAC,sBAAsBJ,SAAS,CAACK,MAAM,IAAI,eAAe,EAAE,CAAC;IAC9E;IAEA,MAAMC,IAAI,GAAG,MAAMf,QAAQ,CAACU,IAAI,CAAC,CAAC;IAClC,MAAMM,KAAK,GAAGD,IAAI,CAACE,EAAE;;IAErB;IACA,OAAO,MAAMC,iBAAiB,CAACF,KAAK,CAAC;EACvC,CAAC,CAAC,OAAOJ,KAAK,EAAE;IACdD,OAAO,CAACC,KAAK,CAAC,iCAAiC,EAAEA,KAAK,CAAC;IACvD,MAAMA,KAAK;EACb;AACF,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA,MAAMM,iBAAiB,GAAG,MAAOF,KAAK,IAAK;EACzC,MAAMe,WAAW,GAAG,EAAE;EACtB,MAAMC,OAAO,GAAG,IAAI;EAEpB,KAAK,IAAIC,OAAO,GAAG,CAAC,EAAEA,OAAO,GAAGF,WAAW,EAAEE,OAAO,EAAE,EAAE;IACtD,IAAI;MACF,MAAMjC,QAAQ,GAAG,MAAMC,KAAK,CAAC,+CAA+Ce,KAAK,EAAE,EAAE;QACnFd,MAAM,EAAE,KAAK;QACbC,OAAO,EAAE;UACP,eAAe,EAAE,UAAUP,eAAe;QAC5C;MACF,CAAC,CAAC;MAEF,IAAI,CAACI,QAAQ,CAACQ,EAAE,EAAE;QAChB,MAAMC,SAAS,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;QACvCC,OAAO,CAACC,KAAK,CAAC,qCAAqCqB,OAAO,GAAG,CAAC,IAAI,EAAExB,SAAS,CAAC;QAC9E;MACF,CAAC,MAAM;QACL,MAAMM,IAAI,GAAG,MAAMf,QAAQ,CAACU,IAAI,CAAC,CAAC;QAElC,IAAIK,IAAI,CAACmB,MAAM,KAAK,WAAW,EAAE;UAC/B,OAAOnB,IAAI,CAACoB,MAAM,CAACX,MAAM;QAC3B,CAAC,MAAM,IAAIT,IAAI,CAACmB,MAAM,KAAK,QAAQ,EAAE;UACnC,MAAM,IAAIrB,KAAK,CAAC,uBAAuBE,IAAI,CAACH,KAAK,IAAI,eAAe,EAAE,CAAC;QACzE;QACA;MACF;IACF,CAAC,CAAC,OAAOA,KAAK,EAAE;MACdD,OAAO,CAACC,KAAK,CAAC,4BAA4BqB,OAAO,GAAG,CAAC,GAAG,EAAErB,KAAK,CAAC;MAChE;IACF;;IAEA;IACA,MAAM,IAAIwB,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAEL,OAAO,CAAC,CAAC;EAC5D;EAEA,MAAM,IAAInB,KAAK,CAAC,2BAA2BkB,WAAW,WAAW,CAAC;AACpE,CAAC;;AAED;AACA;AACA;AACA,OAAO,MAAMQ,2BAA2B,GAAIxC,eAAe,IAAK;EAC9D,OAAO,IAAIqC,OAAO,CAAEC,OAAO,IAAK;IAC9BC,UAAU,CAAC,MAAM;MACf;MACA,MAAME,WAAW,GAAG;QAClB,eAAe,EAAE,sOAAsO;QACvP,kBAAkB,EAAE,uUAAuU;QAC3V,oBAAoB,EAAE,6UAA6U;QACnW,QAAQ,EAAE;MACZ,CAAC;;MAED;MACA,IAAIC,UAAU,GAAG,2DAA2D;MAE5E,KAAK,MAAM,CAACC,GAAG,EAAEC,KAAK,CAAC,IAAIC,MAAM,CAACC,OAAO,CAACL,WAAW,CAAC,EAAE;QACtD,IAAIzC,eAAe,CAAC+C,WAAW,CAAC,CAAC,CAACC,QAAQ,CAACL,GAAG,CAAC,EAAE;UAC/CD,UAAU,GAAGE,KAAK;UAClB;QACF;MACF;;MAEA;MACA,IAAIF,UAAU,KAAK,2DAA2D,EAAE;QAC9EA,UAAU,GAAG,mHAAmH;MAClI;MAEAJ,OAAO,CAACI,UAAU,CAAC;IACrB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC;AACJ,CAAC;;AAED;AACA;AACA;AACA,OAAO,MAAMO,qBAAqB,GAAGA,CAAC5B,cAAc,EAAEC,YAAY,KAAK;EACrE,OAAO,IAAIe,OAAO,CAAEC,OAAO,IAAK;IAC9BC,UAAU,CAAC,MAAM;MACf;MACA,MAAMW,UAAU,GAAG5B,YAAY,CAACE,GAAG,CAACC,MAAM,IAAIA,MAAM,CAACC,KAAK,CAACC,IAAI,CAAC;MAChE,MAAMwB,cAAc,GAAG;AAC7B;AACA;AACA,EAAE7B,YAAY,CAACE,GAAG,CAAC,CAACC,MAAM,EAAE2B,KAAK,KAAK;AACtC,MAAM3B,MAAM,CAACC,KAAK,CAACC,IAAI;AACvB,8BAA8B,CAAC,GAAG0B,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC;AAC/D,2BAA2B,CAAC,GAAGF,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC;AAC5D,iBAAiB,CAAC,GAAGF,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC;AAClD,mBAAmB,CAAC,GAAGF,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC;AACpD;AACA,iBAAiBC,iBAAiB,CAAC/B,MAAM,CAACC,KAAK,CAACC,IAAI,CAAC;AACrD,kBAAkB8B,iBAAiB,CAAChC,MAAM,CAACC,KAAK,CAACC,IAAI,CAAC;AACtD,CAAC,CAAC,CAACC,IAAI,CAAC,EAAE,CAAC;AACX;AACA;AACA;AACA,4DAA4DP,cAAc,CAACqC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC;AAC3F;AACA,EAAER,UAAU,CAAC,CAAC,CAAC,aAAaG,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,GAAG,GAAG,mBAAmB,GAAG,iBAAiB,oBAAoBL,UAAU,CAACA,UAAU,CAACS,MAAM,GAAC,CAAC,CAAC,IAAIN,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,GAAG,GAAG,yBAAyB,GAAG,iCAAiC;AACnO;AACA;AACA;AACA,KAAKL,UAAU,CAACG,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAGL,UAAU,CAACS,MAAM,CAAC,CAAC,qBAAqBN,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC;AACpH,EAAEL,UAAU,CAACU,KAAK,CAAC,CAAC,EAAEV,UAAU,CAACS,MAAM,GAAC,CAAC,CAAC,CAACnC,GAAG,CAAC,CAACG,IAAI,EAAEkC,GAAG,KAAK,GAAGA,GAAG,GAAC,CAAC,KAAKlC,IAAI,qBAAqB0B,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC3B,IAAI,CAAC,IAAI,CAAC;AACtJ,OAAO;MAEDU,OAAO,CAACa,cAAc,CAAC;IACzB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC;AACJ,CAAC;;AAED;AACA,SAASK,iBAAiBA,CAACM,SAAS,EAAE;EACpC,MAAMC,SAAS,GAAG,CAChB,0CAA0C,EAC1C,yCAAyC,EACzC,uDAAuD,EACvD,+CAA+C,EAC/C,oDAAoD,CACrD;EACD,OAAOA,SAAS,CAACV,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAGQ,SAAS,CAACJ,MAAM,CAAC,CAAC;AAChE;AAEA,SAASF,iBAAiBA,CAACK,SAAS,EAAE;EACpC,MAAME,UAAU,GAAG,CACjB,gDAAgD,EAChD,uCAAuC,EACvC,+CAA+C,EAC/C,iDAAiD,EACjD,sDAAsD,CACvD;EACD,OAAOA,UAAU,CAACX,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAGS,UAAU,CAACL,MAAM,CAAC,CAAC;AAClE","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}